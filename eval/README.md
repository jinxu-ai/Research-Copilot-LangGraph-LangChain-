# eval/

This directory holds evaluation datasets and scripts.

- `dataset.jsonl` — benchmark questions with reference points.
- `run_eval.py` — run experiments (baseline vs iterative vs retriever).
- `report.md` — results and analysis.

Use this folder to assess system performance and document improvements.
